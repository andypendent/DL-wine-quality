{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "path = '/Users/Andy/Documents/_BeCode/becode_projects/DL-wine-quality/Wine Quality/wine.csv'\n",
    "df = pd.read_csv(path)\n",
    "df = df.drop(['index'],axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6497, 12)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6497, 11) (6497,)\n"
     ]
    }
   ],
   "source": [
    "# create feature and target Data\n",
    "# Input 'X' is all but the last column\n",
    "# Output 'y' is the last column = 'quality'\n",
    "\n",
    "X = df.iloc[:, 0:-1]\n",
    "y = df.iloc[:, -1]\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5197, 11)\n",
      "(1300, 11)\n",
      "(5197,)\n",
      "(1300,)\n"
     ]
    }
   ],
   "source": [
    "# split into train and test\n",
    "# => Because there’s a class imbalance,\n",
    "# we want to have equal distribution of all output classes in our train and test sets.\n",
    "# To do that, we use the 'stratify' option in function 'train_test_split()'\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=69)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.31404959, 0.16      , 0.21686747, ..., 0.38582677, 0.16853933,\n",
       "         0.47826087],\n",
       "        [0.26446281, 0.22666667, 0.11445783, ..., 0.51181102, 0.19101124,\n",
       "         0.42028986],\n",
       "        [0.49586777, 0.28      , 0.20481928, ..., 0.39370079, 0.21348315,\n",
       "         0.24637681],\n",
       "        ...,\n",
       "        [0.23140496, 0.05333333, 0.24096386, ..., 0.62992126, 0.16853933,\n",
       "         0.63768116],\n",
       "        [0.23140496, 0.10666667, 0.1626506 , ..., 0.39370079, 0.16292135,\n",
       "         0.17391304],\n",
       "        [0.38842975, 0.06666667, 0.18072289, ..., 0.07086614, 0.07865169,\n",
       "         0.28985507]]),\n",
       " array([[0.47933884, 0.4       , 0.14457831, ..., 0.31496063, 0.21348315,\n",
       "         0.31884058],\n",
       "        [0.2892562 , 0.08666667, 0.19879518, ..., 0.29133858, 0.16853933,\n",
       "         0.31884058],\n",
       "        [0.2231405 , 0.16666667, 0.43373494, ..., 0.27559055, 0.19662921,\n",
       "         0.2173913 ],\n",
       "        ...,\n",
       "        [0.29752066, 0.05333333, 0.1626506 , ..., 0.12598425, 0.11797753,\n",
       "         0.10144928],\n",
       "        [0.26446281, 0.08666667, 0.1686747 , ..., 0.4015748 , 0.17977528,\n",
       "         0.34782609],\n",
       "        [0.28099174, 0.12666667, 0.1686747 , ..., 0.33858268, 0.09550562,\n",
       "         0.42028986]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize Input\n",
    "# Neural networks need data that lies between the range of (0,1)\n",
    "# To scale values, we’ll use the MinMaxScaler()\n",
    "# Notice that we use .fit_transform() on X_train while we use .transform() on X_test.\n",
    "# We do this because we want to scale the test set with the same parameters as that of the train set to avoid data leakage.\n",
    "# .fit_transform calculates scaling values and applies them,\n",
    "# while .transform only applies the calculated values.\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test: Counter({6: 567, 5: 428, 7: 216, 4: 43, 8: 39, 3: 6, 9: 1})\n",
      "y_train: Counter({6: 2269, 5: 1710, 7: 863, 4: 173, 8: 154, 3: 24, 9: 4})\n"
     ]
    }
   ],
   "source": [
    "# nbr of samples per class in y_train, y_test\n",
    "print(f'y_test: {Counter(y_test)}')\n",
    "print(f'y_train: {Counter(y_train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      3  4  5  6  7  8  9\n",
       " 2811  0  0  0  1  0  0  0\n",
       " 1284  0  0  1  0  0  0  0\n",
       " 943   0  0  0  0  1  0  0\n",
       " 4525  0  0  0  0  0  1  0\n",
       " 5779  0  0  0  1  0  0  0\n",
       " ...  .. .. .. .. .. .. ..\n",
       " 2713  0  1  0  0  0  0  0\n",
       " 875   0  0  0  0  1  0  0\n",
       " 1612  0  0  0  0  1  0  0\n",
       " 1732  0  0  1  0  0  0  0\n",
       " 5313  0  1  0  0  0  0  0\n",
       " \n",
       " [5197 rows x 7 columns],\n",
       "       3  4  5  6  7  8  9\n",
       " 475   0  0  1  0  0  0  0\n",
       " 4459  0  0  0  1  0  0  0\n",
       " 2245  0  1  0  0  0  0  0\n",
       " 5487  0  0  0  1  0  0  0\n",
       " 5410  0  0  1  0  0  0  0\n",
       " ...  .. .. .. .. .. .. ..\n",
       " 2399  0  0  0  1  0  0  0\n",
       " 2636  0  0  1  0  0  0  0\n",
       " 5652  0  0  0  0  1  0  0\n",
       " 2022  0  0  0  1  0  0  0\n",
       " 4947  0  0  0  1  0  0  0\n",
       " \n",
       " [1300 rows x 7 columns])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'one hot' encode y_train_res, y_test\n",
    "y_train = pd.get_dummies(y_train)\n",
    "y_test = pd.get_dummies(y_test)\n",
    "y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform X_train, y_train and their test counterparts into pytorch tensors using torch.tensor()\n",
    "# => before convert to np.array()\n",
    "# make sure to convert them to float\n",
    "\n",
    "X_train = torch.tensor(np.array(X_train), dtype=torch.float64)\n",
    "y_train = torch.tensor(np.array(y_train), dtype=torch.float64)\n",
    "X_test = torch.tensor(np.array(X_test), dtype=torch.float64)\n",
    "y_test = torch.tensor(np.array(y_test), dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3140, 0.1600, 0.2169, 0.0153, 0.0515, 0.1076, 0.3433, 0.1136, 0.3858,\n",
       "         0.1685, 0.4783],\n",
       "        [0.2645, 0.2267, 0.1145, 0.0261, 0.1030, 0.0590, 0.0691, 0.1475, 0.5118,\n",
       "         0.1910, 0.4203],\n",
       "        [0.4959, 0.2800, 0.2048, 0.0261, 0.1412, 0.0312, 0.0899, 0.2223, 0.3937,\n",
       "         0.2135, 0.2464],\n",
       "        [0.1157, 0.0500, 0.1988, 0.0153, 0.0316, 0.0417, 0.1221, 0.0509, 0.4409,\n",
       "         0.3483, 0.5652],\n",
       "        [0.2231, 0.1533, 0.3675, 0.1902, 0.0731, 0.1042, 0.2696, 0.1922, 0.2756,\n",
       "         0.1573, 0.1884]], dtype=torch.float64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 11)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define NN params\n",
    "nb_hidden_neurons_1 = 288\n",
    "nb_hidden_neurons_2 = int(nb_hidden_neurons_1 / 2)\n",
    "nb_hidden_neurons_3 = int(nb_hidden_neurons_2 / 2)\n",
    "\n",
    "nb_classes = len(pd.unique(df['quality']))\n",
    "nb_features = X_train.shape[1]\n",
    "nb_classes, nb_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create NN architecture\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class Network(nn.Module):\n",
    "\n",
    "    def __init__(self, nb_features):\n",
    "        \"\"\"Here we define the layers\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "        # class torch.nn.Linear(in_features: int, out_features: int, bias: bool = True = default)\n",
    "        \n",
    "        self.layer_1 = nn.Linear(nb_features, nb_hidden_neurons_1)  \n",
    "        self.layer_2 = nn.Linear(nb_hidden_neurons_1, nb_hidden_neurons_2)\n",
    "        self.layer_3 = nn.Linear(nb_hidden_neurons_2, nb_hidden_neurons_3)\n",
    "        self.layer_4 = nn.Linear(nb_hidden_neurons_3, nb_classes)\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        \"\"\"Here we combine the layers\n",
    "        \"\"\"\n",
    "        \n",
    "        activation_function = nn.Sigmoid()  #nn.ReLU()\n",
    "        last_layer_activation = nn.Softmax(dim=1)\n",
    "        \n",
    "        output_first_layer = activation_function(self.layer_1(x)) \n",
    "        output_second_layer = activation_function(self.layer_2(output_first_layer))\n",
    "        output_third_layer = activation_function(self.layer_3(output_second_layer))\n",
    "        prediction = last_layer_activation(self.layer_4(output_third_layer))\n",
    "        \n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (layer_1): Linear(in_features=11, out_features=288, bias=True)\n",
       "  (layer_2): Linear(in_features=288, out_features=144, bias=True)\n",
       "  (layer_3): Linear(in_features=144, out_features=72, bias=True)\n",
       "  (layer_4): Linear(in_features=72, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_nn = Network(nb_features)\n",
    "my_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0075\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Select:\n",
    "criterion =  nn.MSELoss()  #nn.BCELoss() # #nn.CrossEntropyLoss()\n",
    "\n",
    "learning_rate = 0.0075\n",
    "optimizer = torch.optim.Adam(my_nn.parameters(), learning_rate)\n",
    "\n",
    "epochs = 1000\n",
    "batch_size = 50\n",
    "\n",
    "print(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train NN\n",
    "\n",
    "def training(batch_size : int, nb_steps_loss_sum : int):\n",
    "    \"\"\" Train the neural network, feeding it `batch_size` at a time\n",
    "    and saving statistics every `nb_steps_loss_sum` steps.\n",
    "    \n",
    "    Arguments:\n",
    "    \n",
    "    - batch_size [int] : the number of input samples at each training step (called a batch)\n",
    "    - nb_steps_loss_sum [int] : the number of batches before saving the loss for plotting\n",
    "    \n",
    "    Returns:\n",
    "    - loss_list : [List[double]] : value of the loss every `nb_steps_loss_sum` steps\n",
    "    \"\"\"\n",
    "\n",
    "    loss_list = []\n",
    "    running_loss = 0\n",
    "    batch_nb = 0\n",
    "\n",
    "    for epoch in range(0,epochs): # Number of times to iterate through the complete dataset\n",
    "        for idx in range(0, X_train.shape[0], batch_size):\n",
    "            \n",
    "            # Get input and output\n",
    "            input_batch = X_train[idx:idx + batch_size]\n",
    "            target = y_train[idx:idx + batch_size]\n",
    "            \n",
    "            # TO COMPLETE:\n",
    "            # - zero gradient buffers\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # - compute the forward pass\n",
    "            y_pred = my_nn(input_batch.float())\n",
    "            \n",
    "            # - compute the loss\n",
    "            loss = criterion(y_pred, target.float())\n",
    "            \n",
    "            # - backpropagate\n",
    "            loss.backward()\n",
    "            \n",
    "            # - do a step => update gradients\n",
    "            optimizer.step()\n",
    "          \n",
    "            \n",
    "            # Save the loss every `running_loss_steps` batches\n",
    "            running_loss += loss.item()\n",
    "            save_loss_condition = batch_nb % nb_steps_loss_sum == (nb_steps_loss_sum - 1)\n",
    "            if save_loss_condition:    \n",
    "                loss_list.append(running_loss)\n",
    "                running_loss = 0.0\n",
    "\n",
    "\n",
    "            batch_nb += 1\n",
    "        \n",
    "    return loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nb_steps_loss_sum = 10\n",
    "batch_size = batch_size\n",
    "\n",
    "loss = training(batch_size=batch_size, nb_steps_loss_sum=nb_steps_loss_sum)\n",
    "\n",
    "# Plotting the loss over training\n",
    "plt.figure()\n",
    "plt.plot(range(0, len(loss)), loss)\n",
    "plt.xlabel(f\"Batches/{nb_steps_loss_sum}\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training loss\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the NN accuracy\n",
    "def computeScore(X, y):\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    batch_size = 1\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx in range(0, X.shape[0], batch_size):\n",
    "            # TO COMPLETE:\n",
    "            # - get the `batch_size` number of input samples\n",
    "            input_batch = X[idx:idx + batch_size]\n",
    "            target = y[idx:idx + batch_size]\n",
    "            \n",
    "            # - compute the prediction of the neural network\n",
    "            y_pred = my_nn(input_batch.float())\n",
    "            \n",
    "            # - get the max of the prediction (e.g. get the most likely class)\n",
    "            # This can be done using 'torch.max'\n",
    "            y_pred_max = torch.max(y_pred, 1).indices\n",
    "            \n",
    "            # - get the max of the target (e.g. correct class)\n",
    "            target_max = torch.max(target, 1).indices\n",
    "            \n",
    "            # - check if the prediction is correct and count it\n",
    "            correct += (y_pred_max == target_max).sum().item()\n",
    "            \n",
    "            # - count every sample\n",
    "            total += y_pred.size(0)     #+=batch_size\n",
    "            \n",
    "    accuracy = correct/total * 100\n",
    "    \n",
    "    print(y_pred, target)\n",
    "    print(y_pred_max, target_max)\n",
    "    print(correct, total)\n",
    "    \n",
    "    print(f'Accuracy of the network on the {total} samples: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.0215e-10, 8.9132e-01, 1.0867e-01, 1.0210e-06, 7.1169e-11, 2.9440e-16,\n",
      "         8.1071e-08]]) tensor([[0., 1., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([1]) tensor([1])\n",
      "4812 5197\n",
      "Accuracy of the network on the 5197 samples: 92.59%\n",
      "tensor([[1.6976e-16, 7.5028e-23, 8.6805e-15, 1.0000e+00, 1.6445e-10, 1.1558e-18,\n",
      "         1.1599e-08]]) tensor([[0., 0., 0., 1., 0., 0., 0.]], dtype=torch.float64)\n",
      "tensor([3]) tensor([3])\n",
      "821 1300\n",
      "Accuracy of the network on the 1300 samples: 63.15%\n"
     ]
    }
   ],
   "source": [
    "computeScore(X_train, y_train)\n",
    "computeScore(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_project",
   "language": "python",
   "name": "pytorch_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
